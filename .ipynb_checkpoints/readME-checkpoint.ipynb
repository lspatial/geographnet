{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from sklearn import preprocessing\n",
    "from geographnet.geographnet.model.wdatasampling import DataSamplingDSited\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from torch_geometric.data import NeighborSampler\n",
    "from geographnet.geographnet.model.wsampler import WNeighborSampler\n",
    "import torch\n",
    "from geographnet.geographnet.traintest_pm import train, test\n",
    "from geographnet.geographnet.model.geographpnet import GeoGraphPNet\n",
    "import gc\n",
    "import sys\n",
    "import shutil\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectSites(datain):\n",
    "    sitesDF = datain.drop_duplicates('id').copy()\n",
    "    sgrp = sitesDF['stratified_flag'].value_counts()\n",
    "    sitesDF['stratified_flag_cnt'] = sgrp.loc[sitesDF['stratified_flag']].values\n",
    "    pos1_index = np.where(sitesDF['stratified_flag_cnt'] < 5)[0]\n",
    "    posT_index = np.where(sitesDF['stratified_flag_cnt'] >= 5)[0]\n",
    "    np.random.seed()\n",
    "    trainsiteIndex, testsiteIndex = train_test_split(posT_index, stratify=sitesDF.iloc[posT_index]['stratified_flag'],\n",
    "                                                     test_size=0.15)\n",
    "    selsites = sitesDF.iloc[testsiteIndex]['id']\n",
    "    trainsitesIndex = np.where(~datain['id'].isin(selsites))[0]\n",
    "    indTestsitesIndex = np.where(datain['id'].isin(selsites))[0]\n",
    "    return trainsitesIndex,indTestsitesIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/wkspace/pypackages/geographnetPub/data/test/pmsamples.tar.gz',\n",
       " <http.client.HTTPMessage at 0x7f475b005390>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib \n",
    "url = 'https://github.com/lspatial/geographnet/raw/master/pmdatain.pkl.tar.gz'\n",
    "tarfl='/wkspace/pypackages/geographnetPub/data/test/pmsamples.tar.gz'\n",
    "urllib.request.urlretrieve(url, tarfl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "def untar(fname, dirs):\n",
    "    t = tarfile.open(fname)\n",
    "    t.extractall(path = dirs) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='/wkspace/pypackages/geographnetPub/data/test/'\n",
    "untar(tarfl,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetFl=target+'/pmdatain.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(950283, 72)\n"
     ]
    }
   ],
   "source": [
    "datatar=pd.read_pickle(targetFl)\n",
    "print(datatar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idate', 'id', 'lat', 'lon', 'CO_24h', 'NO2_24h', 'O3_24h', 'O3_8h_24h',\n",
       "       'PM10_24h', 'PM2.5_24h', 'SO2_24h', 'lat2', 'lon2', 'latlon', 'year',\n",
       "       'month', 'day', 'DOY', 'dem', 'OVP10_TOTEXTTAU', 'OVP14_TOTEXTTAU',\n",
       "       'TOTEXTTAU', 'glnaswind', 'maiacaod', 'o3', 'pblh', 'prs', 'rhu', 'tem',\n",
       "       'win', 'GAE', 'NO2_BOT', 'NO_BOT', 'PM25_BOT', 'PM_BOT', 'OVP10_CO',\n",
       "       'OVP10_GOCART_SO2_VMR', 'OVP10_NO', 'OVP10_NO2', 'OVP10_O3', 'BCSMASS',\n",
       "       'DMSSMASS', 'DUSMASS25', 'HNO3SMASS', 'NISMASS25', 'OCSMASS', 'PM25',\n",
       "       'SO2SMASS', 'SSSMASS25', 'sdist_roads', 'sdist_poi', 'parea10km',\n",
       "       'rlen10km', 'wstag', 'wmix', 'CLOUD', 'stratified_flag', 'MYD13C1.NDVI',\n",
       "       'MYD13C1.EVI', 'MOD13C1.NDVI', 'MOD13C1.EVI', 'is_workday', 'OMI-NO2',\n",
       "       'co_log', 'no2_log', 'o3_log', 'o3h24_log', 'pm10_log', 'pm25_log',\n",
       "       'so2_log', 'ratiolog_pm25_pm10', 'sid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatar.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['idate', 'id', 'lat', 'lon', 'CO_24h', 'NO2_24h', 'O3_24h', 'O3_8h_24h',\n",
      "       'PM10_24h', 'PM2.5_24h', 'SO2_24h', 'lat2', 'lon2', 'latlon', 'year',\n",
      "       'month', 'day', 'DOY', 'dem', 'OVP10_TOTEXTTAU', 'OVP14_TOTEXTTAU',\n",
      "       'TOTEXTTAU', 'glnaswind', 'maiacaod', 'o3', 'pblh', 'prs', 'rhu', 'tem',\n",
      "       'win', 'GAE', 'NO2_BOT', 'NO_BOT', 'PM25_BOT', 'PM_BOT', 'OVP10_CO',\n",
      "       'OVP10_GOCART_SO2_VMR', 'OVP10_NO', 'OVP10_NO2', 'OVP10_O3', 'BCSMASS',\n",
      "       'DMSSMASS', 'DUSMASS25', 'HNO3SMASS', 'NISMASS25', 'OCSMASS', 'PM25',\n",
      "       'SO2SMASS', 'SSSMASS25', 'sdist_roads', 'sdist_poi', 'parea10km',\n",
      "       'rlen10km', 'wstag', 'wmix', 'CLOUD', 'stratified_flag', 'MYD13C1.NDVI',\n",
      "       'MYD13C1.EVI', 'MOD13C1.NDVI', 'MOD13C1.EVI', 'is_workday', 'OMI-NO2',\n",
      "       'co_log', 'no2_log', 'o3_log', 'o3h24_log', 'pm10_log', 'pm25_log',\n",
      "       'so2_log', 'ratiolog_pm25_pm10', 'sid'],\n",
      "      dtype='object') (950283, 72)\n",
      "torch.Size([690702]) torch.Size([121889])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conducting  0  of  3  for PM  ... ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [00:39<00:00,  8.51it/s]\n",
      "  0%|          | 0/338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong loop for ecpoch 0, continue ... ...\n",
      "Conducting  1  of  3  for PM  ... ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [00:40<00:00,  8.42it/s]\n",
      "  0%|          | 0/338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong loop for ecpoch 1, continue ... ...\n",
      "Conducting  2  of  3  for PM  ... ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 19/338 [00:06<01:45,  3.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-adc5974283ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# adjust_lr(optimizer, epoch, init_lr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Conducting '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' of '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' for PM  ... ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_pm25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_pm10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_rel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m        permetrics,lossinf,testdata= test(model, x_loader, device, x, y, scy,train_index,\n",
      "\u001b[0;32m/wkspace/pypackages/geographnetPub/geographnet/geographnet/traintest_pm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, device, optimizer, X, y)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0madjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0madj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madjs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# .reshape(-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mpm25\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mpm10\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(datatar.columns,datatar.shape)\n",
    "covs=['idate','lat', 'lon', 'latlon', 'DOY', 'dem', 'OVP10_TOTEXTTAU', 'OVP14_TOTEXTTAU',\n",
    "       'TOTEXTTAU', 'glnaswind', 'maiacaod', 'o3', 'pblh', 'prs', 'rhu', 'tem',\n",
    "       'win', 'GAE', 'NO2_BOT', 'NO_BOT', 'PM25_BOT', 'PM_BOT', 'OVP10_CO',\n",
    "       'OVP10_GOCART_SO2_VMR', 'OVP10_NO', 'OVP10_NO2', 'OVP10_O3', 'BCSMASS',\n",
    "       'DMSSMASS', 'DUSMASS25', 'HNO3SMASS', 'NISMASS25', 'OCSMASS', 'PM25',\n",
    "       'SO2SMASS', 'SSSMASS25', 'sdist_roads', 'sdist_poi', 'parea10km',\n",
    "       'rlen10km', 'wstag', 'wmix', 'CLOUD', 'MYD13C1.NDVI',\n",
    "       'MYD13C1.EVI', 'MOD13C1.NDVI', 'MOD13C1.EVI', 'is_workday', 'OMI-NO2']\n",
    "target=['PM10_24h', 'PM2.5_24h']\n",
    "X = datatar[covs].values\n",
    "scX = preprocessing.StandardScaler().fit(X)\n",
    "Xn = scX.transform(X)\n",
    "y = datatar[['pm25_log','pm10_log']].values\n",
    "ypm25 = datatar['PM2.5_24h'].values\n",
    "ypm10 = datatar['PM10_24h'].values\n",
    "scy = preprocessing.StandardScaler().fit(y)\n",
    "yn = scy.transform(y)\n",
    "tarcols=[i for i in range(len(covs))]\n",
    "trainsitesIndex=[i for i in range(datatar.shape[0])]\n",
    "trainsitesIndex, indTestsitesIndex=selectSites(datatar)\n",
    "x, edge_index,edge_dist, y, train_index, test_index = DataSamplingDSited(Xn[:,tarcols], yn, [0,1,2], 12,\n",
    "                        trainsitesIndex ,datatar)\n",
    "Xn = Xn[:, 1:]\n",
    "edge_weight=1.0/(edge_dist+0.00001)\n",
    "neighbors=[12,12,12,12]\n",
    "train_loader = WNeighborSampler(edge_index, edge_weight= edge_weight,node_idx=train_index,\n",
    "                               sizes=neighbors, batch_size=2048, shuffle=True,\n",
    "                               num_workers=20 )\n",
    "x_index = torch.LongTensor([i for i in range(Xn.shape[0])])\n",
    "x_loader = WNeighborSampler(edge_index, edge_weight= edge_weight,node_idx=x_index,\n",
    "                           sizes=neighbors, batch_size=2048, shuffle=False,\n",
    "                           num_workers=20 )\n",
    "gpu=0\n",
    "if gpu is None:\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cuda:'+str(gpu))\n",
    "nout=2\n",
    "resnodes = [512, 320, 256, 128, 96, 64, 32, 16]\n",
    "# 0: original; 1: concated ; 2: dense; 3: only gcn\n",
    "gcnnhiddens = [128,64,32]\n",
    "model = GeoGraphPNet(x.shape[1], gcnnhiddens, nout, len(neighbors), resnodes, weightedmean=True,gcnout=nout,nattlayer=1)\n",
    "model = model.to(device)\n",
    "x = x.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "y = y.to(device)\n",
    "init_lr=0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "best_indtest_r2 = -9999\n",
    "best_indtest_r2_pm10=-9999\n",
    "scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min')\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2, last_epoch=-1)\n",
    "oldlr=newlr=init_lr\n",
    "epoch=0\n",
    "nepoch=3\n",
    "trpath=\"/wkspace/pypackages/geographnetPub/data/test\"\n",
    "while epoch< nepoch  :\n",
    "    # adjust_lr(optimizer, epoch, init_lr)\n",
    "    print('Conducting ',epoch, ' of ',nepoch,' for PM  ... ...')\n",
    "    loss,loss_pm25,loss_pm10,loss_rel = train(model, train_loader, device, optimizer, x, y)\n",
    "\n",
    "    permetrics, lossinf, testdata = test(model, x_loader, device, x, y, scy, train_index,\n",
    "                                         test_index, indtest_index=indTestsitesIndex,\n",
    "                                         ypm25=ypm25, ypm10=ypm10)\n",
    "\n",
    "    try:\n",
    "       permetrics,lossinf,testdata= test(model, x_loader, device, x, y, scy,train_index,\n",
    "                         test_index, testout=True,indtest_index=indTestsitesIndex,\n",
    "                         ypm25=ypm25 ,ypm10=ypm10)\n",
    "       lossall, lossall_pm25, lossall_pm10, lossall_rel = lossinf\n",
    "       pmindtesting, pmtesting, pmtrain=testdata\n",
    "    except:\n",
    "        print(\"Wrong loop for ecpoch \"+str(epoch)+ \", continue ... ...\")\n",
    "        epoch=epoch+1\n",
    "        continue\n",
    "    permetrics_pm25 = permetrics[permetrics['pol'] == 'pm2.5']\n",
    "    permetrics_pm10 = permetrics[permetrics['pol'] == 'pm10']\n",
    "    permetrics_pm25=permetrics_pm25.iloc[0]\n",
    "    permetrics_pm10 = permetrics_pm10.iloc[0]\n",
    "    if epoch>15 and permetrics_pm25['train_r2']<0 :\n",
    "        print(\"Abnormal for ecpoch \" + str(epoch) + \", continue ... ...\")\n",
    "        epoch = epoch + 1\n",
    "        continue\n",
    "    if best_indtest_r2 < permetrics_pm25['indtest_r2']:\n",
    "        best_indtest_r2 = permetrics_pm25['indtest_r2']\n",
    "        saveDf = pd.DataFrame({'sid': datatar.iloc[test_index]['sid'].values, 'obs': pmtesting['pm25_obs'].values,\n",
    "                               'pre': pmtesting['pm25_pre'].values})\n",
    "        saveindDf = pd.DataFrame({'sid': datatar.iloc[indTestsitesIndex]['sid'].values, 'obs': pmindtesting['pm25_obs'].values,\n",
    "             'pre': pmindtesting['pm25_pre'].values})\n",
    "        testfl = trpath + '/model_pm25_bestindtest_testdata.csv'\n",
    "        saveDf.to_csv(testfl,index_label='index')\n",
    "        indtestfl = trpath + '/model_pm25_bestindtest_indtestdata.csv'\n",
    "        saveindDf.to_csv(indtestfl, index_label='index')\n",
    "        modelFl = trpath + '/model_pm25_bestindtestr2.tor'\n",
    "        torch.save(model, modelFl)\n",
    "        modelMeFl = trpath + '/model_pm25_bestindtestr2.csv'\n",
    "        pd.DataFrame([permetrics_pm25.to_dict()]).to_csv(modelMeFl, index_label='epoch')\n",
    "\n",
    "    if best_indtest_r2_pm10 < permetrics_pm10['indtest_r2']:\n",
    "        best_indtest_r2_pm10 = permetrics_pm10['indtest_r2']\n",
    "        saveDf = pd.DataFrame({'sid': datatar.iloc[test_index]['sid'].values, 'obs': pmtesting['pm10_obs'].values,\n",
    "                               'pre': pmtesting['pm10_pre'].values})\n",
    "        saveindDf = pd.DataFrame(\n",
    "            {'sid': datatar.iloc[indTestsitesIndex]['sid'].values, 'obs': pmindtesting['pm10_obs'].values,\n",
    "             'pre': pmindtesting['pm10_pre'].values})\n",
    "        testfl = trpath + '/model_pm10_bestindtest_testdata.csv'\n",
    "        saveDf.to_csv(testfl, index_label='index')\n",
    "        indtestfl = trpath + '/model_pm10s_bestindtest_indtestdata.csv'\n",
    "        saveindDf.to_csv(indtestfl, index_label='index')\n",
    "        modelFl = trpath + '/model_pm10_bestindtestr2.tor'\n",
    "        torch.save(model, modelFl)\n",
    "        modelMeFl = trpath + '/model_pm10_bestindtestr2.csv'\n",
    "        pd.DataFrame([permetrics_pm10.to_dict()]).to_csv(modelMeFl, index_label='epoch')\n",
    "    scheduler.step(loss)\n",
    "    newlr= optimizer.param_groups[0]['lr']\n",
    "    if newlr!=oldlr:\n",
    "        print('Learning rate is {} from {} '.format(newlr, oldlr))\n",
    "        oldlr=newlr\n",
    "    atrainDf=permetrics\n",
    "    atrainDf['epoch']=epoch\n",
    "    lossDf=pd.DataFrame({'epoch':epoch,'loss':loss, 'loss_pm25':loss_pm25,'loss_pm10':loss_pm10,\n",
    "                         'loss_rel':loss_rel,'lossall':lossall,'lossall_pm25':lossall_pm25,\n",
    "                         'lossall_pm10':lossall_pm10,'lossall_rel':lossall_rel},index=[epoch])\n",
    "    print(permetrics)\n",
    "    print(lossDf)\n",
    "    if epoch==0:\n",
    "        alltrainHist=atrainDf\n",
    "        alllostinfo=lossDf\n",
    "    else:\n",
    "        alltrainHist=alltrainHist.append(atrainDf)\n",
    "        alllostinfo = alllostinfo.append(lossDf)\n",
    "    epoch=epoch+1\n",
    "tfl = trpath + '/trainHist.csv'\n",
    "alltrainHist.to_csv(tfl, header=True, index_label=\"row\")\n",
    "tfl = trpath + '/ftrain_loss.csv'\n",
    "alllostinfo.to_csv(tfl, header=True, index_label=\"row\")\n",
    "del optimizer, x, edge_index, y, train_index, test_index, model, alltrainHist\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python37Dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
